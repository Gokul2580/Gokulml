8. EM and K means 
 
Aim: 
To implement k-means algorithm to cluster a set of data stored in a .CSV file and 
use the same data set for clustering using the EM algorithm.  
 
Algorithm: 
 
K-means Algorithm: 
Step 1: Choose the number of clusters, K. 
Step 2: Initialize centroids: Randomly pick K data points as initial cluster 
centroids. 
Step 3: Assign clusters: Assign each data point to the nearest centroid (typically 
using Euclidean distance). 
Step 4: Update centroids: Calculate new centroids by averaging all points 
assigned to each cluster. 
Step 4: Repeat steps 3 and 4 until: 
● Centroids no longer change significantly, or 
● A maximum number of iterations is reached. 
●  
EM Algorithm: 
The EM algorithm alternates between two steps until convergence: 
E-step (Expectation): 
○ Estimate the expected value of the log-likelihood, using the current 
estimates of the parameters. 
○ Essentially, calculate the probabilities (or responsibilities) that each 
data point belongs to a certain hidden category (e.g., cluster). 
2. M-step (Maximization): 
○ Maximize the expected log-likelihood found in the E-step to update 
the parameters. 
This process continues until the parameter estimates converge. 
Training Samples: 
sepal_length,sepal_width,petal_length,petal_width,species 
5.1,3.5,1.4,0.2,setosa 
4.9,3.0,1.4,0.2,setosa 
4.7,3.2,1.3,0.2,setosa 
4.6,3.1,1.5,0.2,setosa 
5.0,3.6,1.4,0.2,setosa 
Program: 
import matplotlib.pyplot as plt 
from sklearn import datasets 
from sklearn.cluster import KMeans 
import sklearn.metrics as sm 
import pandas as pd 
import numpy as np 
iris = datasets.load_iris() 
X = pd.DataFrame(iris.data) 
X.columns = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width'] 
y = pd.DataFrame(iris.target) 
y.columns = ['Targets'] 
model = KMeans(n_clusters=3) 
model.fit(X) 
plt.figure(figsize=(14,7)) 
colormap = np.array(['red', 'lime', 'black']) 
# Plot the Original Classifications 
plt.subplot(1, 2, 1) 
plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[y.Targets], s=40) 
plt.title('Real Classification') 
plt.xlabel('Petal Length') 
plt.ylabel('Petal Width') 
# Plot the Models Classifications 
plt.subplot(1, 2, 2) 
plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[model.labels_], s=40) 
plt.title('K Mean Classification') 
plt.xlabel('Petal Length') 
plt.ylabel('Petal Width') 
print('The accuracy score of K-Means: ',sm.accuracy_score(y, model.labels_)) 
print('The Confusion matrix of K-Means: ',sm.confusion_matrix(y, model.labels_)) 
from sklearn import preprocessing 
scaler = preprocessing.StandardScaler() 
scaler.fit(X) 
xsa = scaler.transform(X) 
xs = pd.DataFrame(xsa, columns = X.columns) 
#xs.sample(5) 
from sklearn.mixture import GaussianMixture 
gmm = GaussianMixture(n_components=3) 
gmm.fit(xs) 
y_gmm = gmm.predict(xs) 
#y_cluster_gmm 
plt.subplot(2, 2, 3) 
plt.scatter(X.Petal_Length, X.Petal_Width, c=colormap[y_gmm], s=40) 
plt.title('GMM Classification') 
plt.xlabel('Petal Length') 
plt.ylabel('Petal Width') 
print('The accuracy score of EM: ',sm.accuracy_score(y, y_gmm)) 
print('The Confusion matrix of EM: ',sm.confusion_matrix(y, y_gmm)) 
Output: 
The accuracy score of K-Means:  0.09333333333333334 
The Confusion matrix of K-Means:  [[ 0 50  0] 
[ 3  0 47] 
[36  0 14]] 
The accuracy score of EM:  0.62 
The Confusion matrix of EM:  [[45  0  5] 
[ 0 48  2] 
[ 0 50  0]] 
Result: 
Thus, the k-means algorithm to cluster a set of data stored in a .CSV file and EM 
algorithm using the same data set for clustering is implemented.  
