EXP NO:5 IMPLEMENTATION OF NAIVE BAYESIAN CLASSIFIER  
DATE: 
AIM: 
To implement the Naive Bayesian classifier for a sample training data set stored as 
a .CSV file and compute the accuracy with a few test data sets. 
ALGORITHM: 
1. Load Data: 
● Read training data from a CSV file (or other suitable format). 
● Read test data from a CSV file (or other suitable format). 
● Ensure data is organized with attributes and a class label. 
2. Separate Data by Class: 
● Iterate through the training data. 
● Group data points based on their class labels. 
● Create a dictionary (or similar structure) where keys are class labels and 
values are lists of data points belonging to that class. 
3. Summarize Data: 
○ For each class: 
○ For each attribute: 
○ Calculate the mean of the attribute values. 
○ Calculate the standard deviation of the attribute values. 
○ Store these summaries (mean and standard deviation) in a suitable structure 
(e.g., a nested dictionary). 
4. Calculate Gaussian Probability: 
o Define a function to calculate the Gaussian probability density 
function (PDF): 
o Input: attribute value (x), mean, standard deviation. 
o Output: probability density. 
o Formula: (1 / (sqrt(2 * pi) * stdev)) * exp(-(pow(x - mean, 2) / (2 * 
pow(stdev, 2)))) 
5. Calculate Class Probabilities: 
o For each test data point: 
o For each class: 
o Initialize the class probability to 1. 
o For each attribute: 
o Get the mean and standard deviation for that attribute from the 
summaries. 
o Calculate the Gaussian probability using the attribute value, mean, 
and standard deviation. 
o Multiply the class probability by the calculated Gaussian 
probability. 
o Store the calculated class probabilities for the test data point. 
6. Predict Class Label: 
o For each test data point: 
o Find the class with the highest probability. 
o Assign that class label as the prediction for the test data point. 
7. Calculate Accuracy: 
● Compare the predicted class labels with the actual class labels in the test 
data. 
● Count the number of correct predictions. 
● Calculate the accuracy: (number of correct predictions / total number of 
test data points) * 100. 
8. Output Results: 
● Display the predictions for the test data. 
● Display the calculated accuracy. 
Training Dataset: 
num_pr
 eg 
glucose_c
 onc 
diastolic
 _bp 
thickn
 ess 
insuli
 n 
bmi 
diab_p
 red 
age 
6 
1 
8 
1 
148 
85 
183 
89 
72 
66 
64 
66 
35 
29 
0 
23 
0 
0 
0 
94 
33.6 
26.6 
23.3 
28.1 
0.627 
0.351 
0.672 
0.167 
50 
31 
32 
21 
diabet
 es 
1 
0 
1 
0 
0 137 40 35 168 43.1 2.288 33 1 
5 116 74 0 0 25.6 0.201 30 0 
3 78 50 32 88 31 0.248 26 1 
10 115 0 0 0 35.3 0.134 29 0 
2 197 70 45 543 30.5 0.158 53 1 
 
 
PROGRAM: 
 
# -*- coding: utf-8 -*- 
 
import csv 
import random 
import math 
  
def loadcsv(filename): 
 lines = csv.reader(open(filename, "r")); 
 dataset = list(lines) 
 for i in range(len(dataset)): 
       #converting strings into numbers for processing 
  dataset[i] = [float(x) for x in dataset[i]] 
         
 return dataset 
  
def splitdataset(dataset, splitratio): 
    #67% training size 
 trainsize = int(len(dataset) * splitratio); 
 trainset = [] 
 copy = list(dataset);     
 while len(trainset) < trainsize: 
#generate indices for the dataset list randomly to pick ele for training data 
  index = random.randrange(len(copy));        
  trainset.append(copy.pop(index))     
 return [trainset, copy] 
  
def separatebyclass(dataset): 
 separated = {} #dictionary of classes 1 and 0  
#creates a dictionary of classes 1 and 0 where the values are  
#the instances belonging to each class 
 for i in range(len(dataset)): 
  vector = dataset[i] 
  if (vector[-1] not in separated): 
   separated[vector[-1]] = [] 
  separated[vector[-1]].append(vector) 
 return separated 
  
def mean(numbers): 
 return sum(numbers)/float(len(numbers)) 
  
def stdev(numbers): 
 avg = mean(numbers) 
 variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1) 
 return math.sqrt(variance) 
  
def summarize(dataset): #creates a dictionary of classes 
 summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]; 
 del summaries[-1] #excluding labels +ve or -ve 
 return summaries 
  
def summarizebyclass(dataset): 
 separated = separatebyclass(dataset);  
    #print(separated) 
 summaries = {} 
 for classvalue, instances in separated.items():  
#for key,value in dic.items() 
#summaries is a dic of tuples(mean,std) for each class value         
  summaries[classvalue] = summarize(instances) #summarize is used to cal 
to mean and std 
 return summaries 
  
def calculateprobability(x, mean, stdev): 
 exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2)))) 
 return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent 
  
def calculateclassprobabilities(summaries, inputvector): 
 probabilities = {} # probabilities contains the all prob of all class of test data 
 for classvalue, classsummaries in summaries.items():#class and attribute 
information as mean and sd 
  probabilities[classvalue] = 1 
  for i in range(len(classsummaries)): 
   mean, stdev = classsummaries[i] #take mean and sd of every 
attribute for class 0 and 1 seperaely 
   x = inputvector[i] #testvector's first attribute 
   probabilities[classvalue] *= calculateprobability(x, mean, 
stdev);#use normal dist 
 return probabilities 
    
def predict(summaries, inputvector): #training and test data is passed 
 probabilities = calculateclassprobabilities(summaries, inputvector) 
 bestLabel, bestProb = None, -1 
 for classvalue, probability in probabilities.items():#assigns that class which has he 
highest prob 
  if bestLabel is None or probability > bestProb: 
   bestProb = probability 
   bestLabel = classvalue 
 return bestLabel 
  
def getpredictions(summaries, testset): 
 predictions = [] 
 for i in range(len(testset)): 
  result = predict(summaries, testset[i]) 
  predictions.append(result) 
 return predictions 
  
def getaccuracy(testset, predictions): 
 correct = 0 
 for i in range(len(testset)): 
  if testset[i][-1] == predictions[i]: 
   correct += 1 
 return (correct/float(len(testset))) * 100.0 
  
def main(): 
 filename = 'naivedata.csv' 
 splitratio = 0.67 
 dataset = loadcsv(filename); 
      
 trainingset, testset = splitdataset(dataset, splitratio) 
 print('Split {0} rows into train={1} and test={2} rows'.format(len(dataset), 
len(trainingset), len(testset))) 
 # prepare model 
 summaries = summarizebyclass(trainingset);     
 #print(summaries) 
    # test model 
 predictions = getpredictions(summaries, testset) #find the predictions of test data 
with the training data 
accuracy = getaccuracy(testset, predictions) 
print('Accuracy of the classifier is : {0}%'.format(accuracy)) 
main() 
OUTPUT: 
Split 768 rows into train=514 and test=254 rows 
Accuracy of the classifier is : 73.22834645669292% 
RESULT: 
Thus the program for naïve Bayesian classifier using a sample dataset was 
implemented and executed successfully. 
